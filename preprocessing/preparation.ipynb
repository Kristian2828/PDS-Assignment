{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought fender telecaster salesperson told orig...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>visit son restaurant desert home food authenti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>danielle great job listened cut hair way reque...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saw lot roaches bathroom woke bed large dark s...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ordered pork fried rice beef chow mei fun teri...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  bought fender telecaster salesperson told orig...  negative\n",
       "1  visit son restaurant desert home food authenti...  positive\n",
       "2  danielle great job listened cut hair way reque...  positive\n",
       "3  saw lot roaches bathroom woke bed large dark s...  negative\n",
       "4  ordered pork fried rice beef chow mei fun teri...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/review_2022_clean.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i bought a fender telecaster that the salesper...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is our go to for take out when i visit my...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>danielle did a great job she listened and cut ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we saw a lot of roaches in the bathroom when w...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we ordered pork fried rice and beef chow mei f...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  i bought a fender telecaster that the salesper...  negative\n",
       "1  this is our go to for take out when i visit my...  positive\n",
       "2  danielle did a great job she listened and cut ...  positive\n",
       "3  we saw a lot of roaches in the bathroom when w...  negative\n",
       "4  we ordered pork fried rice and beef chow mei f...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sw = pd.read_csv(\"../data/review_2022_clean_sw.csv\")\n",
    "df_sw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to perform train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(stop_words=False):\n",
    "  if stop_words:\n",
    "    X = df_sw[\"text\"]\n",
    "    y = df_sw[\"label\"]\n",
    "  else:\n",
    "    X = df[\"text\"]\n",
    "    y = df[\"label\"]\n",
    "  return train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sw, X_test_sw, y_train_sw, y_test_sw = split(stop_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for these scenarios:\n",
    "1. unigrams\n",
    "2. unigrams + stop words\n",
    "3. bigrams\n",
    "4. bigrams + stop words\n",
    "5. unigrams + bigrams\n",
    "6. unigrams + bigrams + stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to perform vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(ngram_range=(1, 1), stop_words=False):\n",
    "  print(\"ngram_range:\", ngram_range)\n",
    "  print(\"stop_words:\", stop_words)\n",
    "\n",
    "  tfidf = TfidfVectorizer(ngram_range=ngram_range)\n",
    "  \n",
    "  if stop_words:\n",
    "    X_train_matrix = tfidf.fit_transform(X_train_sw)\n",
    "    X_test_matrix = tfidf.transform(X_test_sw)\n",
    "  else:\n",
    "    X_train_matrix = tfidf.fit_transform(X_train)\n",
    "    X_test_matrix = tfidf.transform(X_test)\n",
    "\n",
    "  print(\"X_train_matrix shape:\", X_train_matrix.shape)\n",
    "  print(\"X_test_matrix shape:\", X_test_matrix.shape)\n",
    "  \n",
    "  return (X_train_matrix, X_test_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range: (1, 1)\n",
      "stop_words: False\n",
      "X_train_matrix shape: (25332, 33634)\n",
      "X_test_matrix shape: (6333, 33634)\n"
     ]
    }
   ],
   "source": [
    "X_train_uni, X_test_uni = vectorize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigrams + Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range: (1, 1)\n",
      "stop_words: True\n",
      "X_train_matrix shape: (25332, 33926)\n",
      "X_test_matrix shape: (6333, 33926)\n"
     ]
    }
   ],
   "source": [
    "X_train_uni_sw, X_test_uni_sw = vectorize(stop_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range: (2, 2)\n",
      "stop_words: False\n",
      "X_train_matrix shape: (25332, 613031)\n",
      "X_test_matrix shape: (6333, 613031)\n"
     ]
    }
   ],
   "source": [
    "X_train_bi, X_test_bi = vectorize((2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigrams + Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range: (2, 2)\n",
      "stop_words: True\n",
      "X_train_matrix shape: (25332, 549842)\n",
      "X_test_matrix shape: (6333, 549842)\n"
     ]
    }
   ],
   "source": [
    "X_train_bi_sw, X_test_bi_sw = vectorize((2, 2), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigrams + Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range: (1, 2)\n",
      "stop_words: False\n",
      "X_train_matrix shape: (25332, 646665)\n",
      "X_test_matrix shape: (6333, 646665)\n"
     ]
    }
   ],
   "source": [
    "X_train_uni_bi, X_test_uni_bi = vectorize((1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unigrams + Bigrams + Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range: (1, 2)\n",
      "stop_words: True\n",
      "X_train_matrix shape: (25332, 583768)\n",
      "X_test_matrix shape: (6333, 583768)\n"
     ]
    }
   ],
   "source": [
    "X_train_uni_bi_sw, X_test_uni_bi_sw = vectorize((1, 2), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to export objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_objects(obj, file_name):\n",
    "  path = \"../data/\" + file_name\n",
    "  with open(path, \"wb\") as f:\n",
    "    pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_list = [\n",
    "  (y_train, \"y_train.pickle\"),\n",
    "  (y_test, \"y_test.pickle\"),\n",
    "  (X_train_uni, \"X_train_uni.pickle\"),\n",
    "  (X_test_uni, \"X_test_uni.pickle\"),\n",
    "  (X_train_uni_sw, \"X_train_uni_sw.pickle\"),\n",
    "  (X_test_uni_sw, \"X_test_uni_sw.pickle\"),\n",
    "  (X_train_bi, \"X_train_bi.pickle\"),\n",
    "  (X_test_bi, \"X_test_bi.pickle\"),\n",
    "  (X_train_bi_sw, \"X_train_bi_sw.pickle\"),\n",
    "  (X_test_bi_sw, \"X_test_bi_sw.pickle\"),\n",
    "  (X_train_uni_bi, \"X_train_uni_bi.pickle\"),\n",
    "  (X_test_uni_bi, \"X_test_uni_bi.pickle\"),\n",
    "  (X_train_uni_bi_sw, \"X_train_uni_bi_sw.pickle\"),\n",
    "  (X_test_uni_bi_sw, \"X_test_uni_bi_sw.pickle\")\n",
    "]\n",
    "\n",
    "for obj, file_name in export_list:\n",
    "  export_objects(obj, file_name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85da4e5205487ecb6868a24591832e66a7808f792e4d3f5382a2652185bc6729"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
